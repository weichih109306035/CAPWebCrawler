{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tc6sd4dJ6xc",
        "outputId": "9ba0c9d8-07c9-49f3-859b-e7d75ac6116a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#定義函數來移除不需要的標籤\n",
        "def remove_unwanted_tags(soup, tags):\n",
        "    for tag in tags:\n",
        "        for match in soup.findAll(tag):\n",
        "            match.decompose()\n",
        "\n",
        "#爬蟲\n",
        "def fetch_news_content(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # 觀察內文在哪些class裡面\n",
        "    content_div = soup.find('div', class_='field-name-body')\n",
        "    if content_div:\n",
        "        content = content_div.find('div', class_='field-item even')\n",
        "        if content:\n",
        "            #金融上雲實例：國泰金控】以雲原生發展多雲混合雲，國泰金自建轉型平臺加速大規模上雲此篇會爬下照片敘述與相關報導字樣，移除\n",
        "            #執行時也不會爬下子標題\n",
        "            remove_unwanted_tags(content, ['a', 'span'])\n",
        "            return content.get_text(separator='\\n', strip=True)\n",
        "\n",
        "    return \"未能找到內文\"\n",
        "\n",
        "#將內文存成txt\n",
        "def save_to_txt(filename, content):\n",
        "    with open(filename, 'w', encoding='utf-8') as file:\n",
        "        file.write(content)\n",
        "\n",
        "#新聞稿URL\n",
        "url_a = \"https://www.ithome.com.tw/news/152373\"\n",
        "url_b = \"https://www.ithome.com.tw/news/159391\"\n",
        "\n",
        "#爬取內文\n",
        "content_a = fetch_news_content(url_a)\n",
        "content_b = fetch_news_content(url_b)\n",
        "\n",
        "#存為txt\n",
        "save_to_txt('news_a1.txt', content_a)\n",
        "save_to_txt('news_b1.txt', content_b)\n",
        "\n",
        "print(\"新聞稿已經成功抓取並存為 txt 檔案。\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3Qsg4WjoG4B",
        "outputId": "260ed4ec-0bff-439b-9fc5-b9db95e19b97"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "新聞稿已經成功抓取並存為 txt 檔案。\n"
          ]
        }
      ]
    }
  ]
}